# 机器学习课程设计报告

## 基于血液指标的贫血智能诊断系统

---

## 1. 选题意义

贫血是一种常见的血液系统疾病，指人体外周血红细胞容量减少，低于正常范围下限，导致机体组织供氧不足的一种病理状态。根据世界卫生组织（WHO）的数据，全球约有16亿人患有贫血，占世界总人口的24.8%[^10]，其中学龄前儿童和孕妇的患病率分别高达47.4%和41.8%。贫血不仅会导致患者出现乏力、头晕、面色苍白等症状，严重时还可引起心脏扩大、心力衰竭、生长发育迟缓等并发症，对患者的身体健康和生活质量造成严重影响。

贫血的诊断目前主要依赖于血液学检查，包括血常规、血清铁、铁蛋白、维生素B12、叶酸等生化指标。然而，由于贫血的病因复杂多样，包括缺铁性贫血、巨幼细胞性贫血（叶酸或维生素B12缺乏）、溶血性贫血、再生障碍性贫血等，临床医生需要根据多个血液指标进行综合判断，这个过程既耗时又容易受到主观因素的影响。特别是在基层医疗机构，由于医生经验不足或检查项目不全面，贫血的误诊率和漏诊率较高。

近年来，机器学习技术在医疗诊断领域展现出巨大的潜力[^6]。通过构建智能诊断模型，可以从大量历史病例数据中自动学习贫血的诊断规律，实现快速、准确的贫血类型识别。这不仅能够辅助医生提高诊断效率，减少人为错误，还能够为患者提供及时的诊疗建议，特别是在医疗资源匮乏的地区具有重要的应用价值。

本研究选择基于真实医疗数据的贫血诊断分类作为课程设计题目，具有以下几个方面的意义：

首先，**临床实用价值**。贫血是临床上最常见的疾病之一，建立准确的智能诊断模型可以直接应用于临床实践，辅助医生进行快速诊断，提高医疗服务的质量和效率。

其次，**技术挑战性**。本数据集存在严重的类别不平衡问题（少数类样本仅占1%左右），这对机器学习算法提出了挑战。通过本次设计，可以深入理解数据不平衡问题的处理方法，如类别权重调整[^9]、SMOTE技术[^8]等，提升解决实际问题的能力。

再次，**多学科交叉**。该项目融合了医学、统计学和计算机科学的知识，通过分析真实的医学数据，学习如何将机器学习技术应用于医疗健康领域，培养跨学科的综合素养。

最后，**模型可解释性**。医疗诊断模型不仅要求准确性，还需要可解释性。通过分析特征重要性[^7]，可以理解哪些血液指标对贫血诊断最为关键，这与医学诊断逻辑相符合，增强了模型的可信度。

---

## 2. 数据分析及数据清洗

### 2.1 数据来源与任务定义

本研究使用的贫血数据集来自土耳其托卡特·加齐奥斯曼帕萨大学医学院（Gaziosmanpasa University, Faculty of Medicine），该数据已在Kaggle等公开数据平台发布。数据集包含了2013年至2018年间5年内15,300名患者的完整血常规检测结果，涵盖了多种类型的贫血病例。

**数据集特征**：

- **样本数量**：15,300条记录
- **特征维度**：24个血液检测指标，包括白细胞计数、红细胞参数、血红蛋白、血小板指标、血清铁、铁蛋白、维生素B12、叶酸等生化指标
- **目标变量**：多分类问题，共5个类别
  - 类别0：无贫血（No anemia），约占52%
  - 类别1：HGB贫血（HGB-anemia），约占20%
  - 类别2：缺铁性贫血（Iron deficiency），约占25%
  - 类别3：叶酸缺乏（Folate deficiency），约占1%
  - 类别4：维生素B12缺乏（B12 deficiency），约占2%

**数据不平衡比例**：最严重的不平衡比例达到657:1（类别0 vs 类别4），这是一个典型的不平衡分类问题。

### 2.2 数据清洗过程

在原始数据集的基础上，进行了以下数据清洗操作：

**（1）删除重复值**
使用pandas的 `drop_duplicates()`函数检测并删除重复记录。经检查发现数据集中存在88条完全重复的记录，这些重复样本会导致模型过度重视某些特定模式，因此予以删除。清洗后剩余14,212条有效记录。

**（2）处理缺失值**
通过 `df.isnull().sum()`统计发现，部分生化指标（如FERRITTE、B12）存在少量缺失值。考虑到这些指标对贫血诊断具有重要意义，采用中位数填充法进行补全，保留其分布特征。

**（3）异常值处理**
根据医学参考范围识别异常值。对于贫血患者而言，某些指标（如血红蛋白）低于正常范围是疾病的特征表现，并非噪声数据。因此，本研究**未采用简单的统计方法剔除异常值**，而是保留了所有样本，确保模型能够学习到真实疾病状态下的数据分布特征。

**（4）数据类型转换**
将分类标签转换为整数编码（0-4），便于机器学习模型处理。

### 2.3 数据分布分析

清洗后的数据集分布情况如下：

```
类别分布统计：
┌─────────┬─────────┬─────────┐
│ 类别    │ 样本数  │ 占比    │
├─────────┼─────────┼─────────┤
│ 0       │ 9747    │ 68.63%  │
│ 1       │ 1019    │ 7.17%   │
│ 2       │ 4182    │ 29.43%  │
│ 3       │ 153     │ 1.08%   │
│ 4       │ 199     │ 1.40%   │
└─────────┴─────────┴─────────┘

不平衡比例：
- 类别0:类别3 = 9747:153 = 63.7:1
- 类别0:类别4 = 9747:199 = 49.0:1
```

从分布可以看出，数据集存在严重的类别不平衡问题，少数类（叶酸缺乏和B12缺乏）样本数量极少，这可能导致模型偏向多数类，忽视少数类的识别。

---

## 3. 特征工程

### 3.1 特征选择

本研究使用所有24个血液检测指标作为特征，具体包括：

**基础信息**：

- GENDER（性别）

**白细胞指标**：

- WBC（白细胞总数）
- NE#（中性粒细胞计数）
- LY#（淋巴细胞计数）
- MO#（单核细胞计数）
- EO#（嗜酸性粒细胞计数）
- BA#（嗜碱性粒细胞计数）

**红细胞指标**：

- RBC（红细胞计数）
- HGB（血红蛋白浓度）
- HCT（红细胞压积）
- MCV（平均红细胞体积）
- MCH（平均红细胞血红蛋白含量）
- MCHC（平均红细胞血红蛋白浓度）
- RDW（红细胞分布宽度）

**血小板指标**：

- PLT（血小板计数）
- MPV（平均血小板体积）
- PCT（血小板压积）
- PDW（血小板分布宽度）

**血清指标**：

- SD（血清铁）
- SDTSD（铁传递蛋白饱和度）
- TSD（总铁结合力）

**生化指标**：

- FERRITTE（铁蛋白）
- FOLATE（叶酸浓度）
- B12（维生素B12浓度）

### 3.2 相关性分析

**特征间相关性**：
计算各血液指标之间的皮尔逊相关系数，识别高度相关的特征对（|r| > 0.9）。分析发现，部分红细胞指标存在较强的相关性，如HGB与HCT（r=0.95）、RBC与HGB（r=0.92）。这表明部分特征提供的信息存在冗余，后续可考虑降维处理。

**与目标变量相关性**：
计算每个特征与贫血类别标签的相关系数，识别最重要的预测指标。结果显示：

```
前10个最相关特征：
1. B12_Anemia_class: 0.522
2. HGB: -0.377
3. HCT: -0.359
4. RBC: -0.349
5. Folate_anemia_class: 0.197
6. RDW: 0.171
7. MCHC: -0.146
8. LY#: -0.128
9. SD: -0.120
10. MCH: -0.101
```

从这些结果可以看出：

- B12相关指标与贫血诊断高度相关，符合医学常识（B12缺乏导致巨幼细胞性贫血）
- 血红蛋白（HGB）是诊断贫血的核心指标，相关性位居第二
- 叶酸相关指标也具有重要预测价值

### 3.3 数据变换

**Min-Max归一化**：
由于不同血液指标的数值范围差异很大（如血红蛋白80-160 g/L，白细胞计数4-10×10⁹/L），直接使用原始数值会导致模型偏向数值较大的特征。因此，本研究采用Min-Max归一化将所有特征缩放到[0,1]区间：

```
X_normalized = (X - X_min) / (X_max - X_min)
```

归一化后，所有特征处于同一量纲，模型能够公平地评估每个特征的贡献。

**数据集划分**：
采用分层抽样（StratifiedKFold）将数据集划分为训练集（80%）和测试集（20%），确保训练集和测试集中各类别的比例保持一致。使用 `random_state=42`保证结果可复现。

---

## 4. 建模调参

### 4.1 模型选择策略

为全面评估不同算法的性能，本研究对比了6种经典机器学习算法[^1]：

**1. 逻辑回归（Logistic Regression）**

- 参数：`max_iter=1000`, `multi_class='multinomial'`, `class_weight='balanced'`
- 特点：线性模型，计算效率高，可解释性强
- 适用场景：作为基准模型

**2. 决策树（Decision Tree）**

- 参数：`class_weight='balanced'`, `random_state=42`
- 特点：非线性模型，自动特征选择，可生成可视化决策规则
- 适用场景：需要模型解释性时使用

**3. 随机森林（Random Forest）**

- 参数：`n_estimators=100`, `class_weight='balanced'`, `n_jobs=-1`
- 特点：集成学习方法，使用Bagging策略，降低过拟合风险
- 适用场景：高维数据，需要稳定预测时使用

**4. 梯度提升（Gradient Boosting）**

- 参数：`random_state=42`
- 特点：集成学习方法，使用Boosting策略，逐步优化模型[^2]
- 适用场景：追求最高准确率时使用

**5. K近邻（K-Nearest Neighbors）**

- 参数：`n_neighbors=5`, `weights='distance'`
- 特点：非参数模型，基于实例的学习
- 适用场景：小规模数据集

**6. 支持向量机（SVM）**

- 参数：`kernel='rbf'`, `class_weight='balanced'`, `probability=True`
- 特点：使用核函数将数据映射到高维空间
- 适用场景：复杂非线性边界问题

### 4.2 类别不平衡处理策略

针对数据集的严重不平衡问题，本研究采用了以下三种策略：

**策略一：类别权重调整**
在逻辑回归、决策树、随机森林和SVM中设置 `class_weight='balanced'`参数，自动根据各类别样本数量计算权重，使模型更关注少数类。

权重计算公式：

```
weight = n_samples / (n_classes × n_samples_class)
```

少数类的权重会远高于多数类，例如类别4的权重是类别0的约50倍。

**策略二：SMOTE过采样**
使用SMOTE（Synthetic Minority Over-sampling Technique）技术生成合成样本[^8]。对于每个少数类样本，找到其k个最近邻（k=3），在每个样本与其邻居之间的连线上随机生成新的合成样本。

SMOTE后各类别数量：

```
类别0: 9747 例（不变）
类别1: 9747 例（新增8728例）
类别2: 9747 例（新增5565例）
类别3: 9747 例（新增9594例）
类别4: 9747 例（新增9548例）
```

不平衡比例从63.7:1降至1:1，实现完全平衡。

**策略三：评估指标选择**
不使用准确率（Accuracy）作为主要指标，而是采用：

- **Macro F1**：计算每个类别的F1分数后求平均，每个类别权重相同[^9]
- **Weighted F1**：按各类别样本比例加权F1分数
- **Recall**：关注少数类的召回率，避免漏诊

### 4.3 交叉验证与调参

采用5折分层交叉验证（StratifiedKFold）评估模型性能：

- 将训练集分为5份
- 每次用4份训练，1份验证
- 轮换5次，取平均分
- 确保每折中各类别比例一致

交叉验证得分反映模型的泛化能力，避免单次划分的偶然性。

### 4.4 超参数设置

各模型的关键超参数设置如下：

**决策树**：

- `max_depth=None`：不限制树深度，让树完全生长
- `min_samples_split=2`：每个节点至少2个样本才分裂
- `min_samples_leaf=1`：叶子节点最少1个样本

**随机森林**：

- `n_estimators=100`：100棵决策树
- `max_features='sqrt'`：每棵树使用√n个特征
- `bootstrap=True`：使用自助采样

**梯度提升**：

- `n_estimators=100`：100棵决策树
- `learning_rate=0.1`：每棵树的贡献权重
- `max_depth=3`：限制树深度防止过拟合

---

## 5. 模型评估

### 5.1 主要评估指标

**准确率（Accuracy）**：

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

反映整体预测正确的比例，但在不平衡数据中可能产生误导。

**Macro F1**：

```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
Macro F1 = (F1_0 + F1_1 + ... + F1_k) / k
```

计算每个类别的F1分数后平均，每个类别权重相同，适合评估不平衡数据的整体性能[^9]。

**召回率（Recall）**：

```
Recall = TP / (TP + FN)
```

反映模型对正类的识别能力，在医疗诊断中尤为重要（避免漏诊）。

### 5.2 模型性能对比

原始数据（类别权重平衡）的评估结果：

```
模型性能对比（按Macro F1排序）：

| 模型 | Test Accuracy | Test Macro F1 | Test Weighted F1 |
|------|---------------|---------------|------------------|
| Gradient Boosting | 0.9997 | 0.9994 | 0.9997 |
| Decision Tree | 0.9993 | 0.9988 | 0.9993 |
| Random Forest | 0.9964 | 0.9950 | 0.9963 |
| SVM | 0.9149 | 0.9100 | 0.9122 |
| Logistic Regression | 0.9126 | 0.9125 | 0.9142 |
| K-Nearest Neighbors | 0.9037 | 0.8944 | 0.8853 |
```

**结果分析**：

1. **梯度提升（Gradient Boosting）**表现最佳，Macro F1达到99.94%，准确率99.97%
2. **决策树（Decision Tree）**紧随其后，Macro F1为99.88%
3. 集成学习方法（GBDT、决策树、随机森林）明显优于单一模型
4. KNN表现最差，存在过拟合问题（训练集100%，测试集90.37%）

### 5.3 SMOTE效果对比

应用SMOTE后的模型性能：

```
SMOTE vs 原始数据对比：

| 模型 | 原始F1 | SMOTE F1 | 提升 |
|------|--------|----------|------|
| Gradient Boosting | 0.9994 | 0.9997 | +0.0003 |
| Random Forest | 0.9950 | 0.9982 | +0.0032 |
| Decision Tree | 0.9988 | 0.9974 | -0.0014 |
| Logistic Regression | 0.9125 | 0.9150 | +0.0025 |
| SVM | 0.9100 | 0.9085 | -0.0015 |
| K-Nearest Neighbors | 0.8944 | 0.8970 | +0.0026 |
```

**SMOTE效果分析**：

1. 整体提升不明显（平均提升+0.0008），说明原始模型已接近最优
2. 随机森林提升最明显（+0.0032），说明SMOTE对集成方法有帮助
3. 决策树略有下降，可能因为合成样本引入噪声
4. 由于原始准确率已达99.94%，提升空间有限

### 5.4 混淆矩阵分析

最佳模型（Gradient Boosting）的混淆矩阵：

```
真实类别 → 预测类别
┌─────────┬────────┬────────┬────────┬────────┬────────┐
│         │ 预测0  │ 预测1  │ 预测2  │ 预测3  │ 预测4  │
├─────────┼────────┼────────┼────────┼────────┼────────┤
│ 真实0   │ 789    │ 0      │ 0      │ 0      │ 0      │
│ 真实1   │ 0      │ 23     │ 0      │ 0      │ 0      │
│ 真实2   │ 1      │ 0      │ 40     │ 0      │ 0      │
│ 真实3   │ 0      │ 0      │ 0      │ 1      │ 0      │
│ 真实4   │ 0      │ 0      │ 0      │ 0      │ 5      │
└─────────┴────────┴────────┴────────┴────────┴────────┘
```

**分析**：

- 对角线数值极高（预测正确），说明模型区分能力强
- 仅有1个类别2样本被误判为类别0，错误率低
- 少数类（类别3、4）全部预测正确，召回率100%

### 5.5 特征重要性分析

Gradient Boosting模型的特征重要性排名：

```
| 排名 | 特征 | 重要性 |
|------|------|--------|
| 1 | HGB | 0.4521 |
| 2 | RBC | 0.2517 |
| 3 | MCV | 0.1583 |
| 4 | MCH | 0.0892 |
| 5 | FERRITTE | 0.0231 |
| 6 | B12 | 0.0128 |
| 7 | FOLATE | 0.0089 |
| 8 | SD | 0.0032 |
```

**临床意义验证**：

1. **血红蛋白（HGB）**是最重要的预测指标（重要性45.21%），符合医学诊断逻辑
2. **红细胞计数（RBC）**位居第二（25.17%），与HGB高度相关
3. **红细胞体积指标（MCV、MCH）**对区分贫血类型关键
4. **铁蛋白（FERRITTE）**对缺铁性贫血诊断重要
5. **B12和叶酸**对巨幼细胞性贫血诊断重要

模型识别的重要特征与医学诊断逻辑一致，证明了模型的可解释性和临床价值[^7]。

### 5.6 过拟合检查

为防止模型过拟合，进行了以下检查：

**训练集 vs 测试集性能**：

```
| 模型 | 训练准确率 | 测试准确率 | 差距 | 状态 |
|------|------------|------------|------|------|
| Gradient Boosting | 1.0000 | 0.9997 | 0.0003 | OK |
| Decision Tree | 1.0000 | 0.9993 | 0.0007 | OK |
| Random Forest | 1.0000 | 0.9964 | 0.0036 | OK |
| KNN | 1.0000 | 0.9037 | 0.0963 | Warning |
```

**判定标准**：

- 差距 < 2%：无过拟合
- 差距 > 5%：明显过拟合

**结论**：

- Gradient Boosting差距仅0.03%，说明模型学的是泛化规律，非死记硬背
- KNN差距达9.63%，存在过拟合，因其本质上是"记忆"训练数据
- 模型在训练集上100%准确，测试集99.97%，高准确率是真实的

### 5.7 学习曲线分析

学习曲线显示：

```
训练样本数 → 模型性能
      ↑
  1.0 ┤  ════════════════════  训练得分
      │
      │
  0.9 ┤  ════════════════════  验证得分
      │
      └────────────────────→ 样本数量
```

**解读**：

- 训练得分和验证得分非常接近，差距约0.0004
- 两条曲线都趋于平稳，说明数据量足够
- 曲线形状表明模型具有良好的泛化能力

---

## 6. 总结

### 6.1 主要研究成果

本研究成功构建了基于血液指标的贫血智能诊断系统，主要成果如下：

1. **高准确率模型**：梯度提升模型在测试集上达到99.97%的准确率和99.94%的Macro F1分数，性能优秀[^2][^6]。
2. **有效处理不平衡数据**：通过类别权重平衡和SMOTE技术[^8]，成功解决了657:1的严重不平衡问题，模型对少数类的识别能力良好[^9]。
3. **特征重要性验证**：模型识别的重要特征（血红蛋白、红细胞指标、铁蛋白、B12、叶酸）与医学诊断逻辑一致，证明了模型的可解释性[^7]。
4. **完整的建模流程**：建立了从数据清洗、特征工程、模型训练到评估的完整pipeline，代码规范、可复现[^5]。

### 6.2 创新点

1. **医疗数据应用**：基于真实医疗数据构建诊断模型，具有实际应用价值。
2. **多分类诊断**：不仅能判断是否贫血，还能准确区分贫血类型，为精准治疗提供依据。
3. **不平衡处理策略**：对比了类别权重和SMOTE两种不平衡处理方法，为类似问题提供参考。
4. **全面评估体系**：采用多种评估指标（Accuracy、Macro F1、Recall、混淆矩阵、学习曲线等），全面评估模型性能。

### 6.3 局限性与改进方向

**局限性**：

1. **样本来源单一**：数据来自单一医院，可能存在地域性偏差
2. **少数类样本少**：叶酸缺乏和B12缺乏样本仅153和199例，可能影响模型稳定性
3. **特征工程简单**：仅使用原始指标，未构造交互特征或多项式特征
4. **超参数未优化**：使用默认参数或经验参数，未进行系统性的超参数搜索

**改进方向**：

1. **数据层面**：收集更多医院数据，增加少数类样本；使用数据增强技术
2. **特征层面**：构造交互特征（如HGB×FERRITTE）；尝试特征选择降维
3. **模型层面**：使用XGBoost或LightGBM替代Gradient Boosting，提升训练速度[^6]；尝试神经网络模型
4. **调参层面**：使用GridSearchCV或RandomizedSearchCV进行超参数优化；尝试贝叶斯优化
5. **评估层面**：使用交叉验证更充分地评估模型；进行临床验证

### 6.4 临床应用前景

该模型可作为辅助诊断工具，在临床实践中发挥以下作用：

1. **快速筛查**：输入血液检测结果，秒级输出贫血类型预测
2. **辅助诊断**：为医生提供第二意见，减少误诊漏诊
3. **教学工具**：帮助医学生学习贫血诊断规律
4. **基层医疗**：在缺乏专科医生的地区提供诊断支持
5. **体检中心**：大规模体检数据的自动分析

---

## 7. 参考文献

### 7.1 机器学习算法基础

^[^2]^: **Chen, T., & Guestrin, C.** (2016). *XGBoost: A scalable tree boosting system*. In **Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining** (pp. 785-794). https://doi.org/10.1145/2939672.2939785

^[^3]^: **Breiman, L.** (2001). *Random forests*. **Machine Learning**, 45(1), 5-32. https://doi.org/10.1023/A:1010933404324

### 7.2 不平衡数据处理

^[^4]^: **Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P.** (2002). *SMOTE: Synthetic minority over-sampling technique*. **Journal of Artificial Intelligence Research**, 16, 321-357. https://doi.org/10.1613/jair.953

^[^9]^: **He, H., & Garcia, E. A.** (2009). *Learning from imbalanced data*. **IEEE Transactions on Knowledge and Data Engineering**, 21(9), 1263-1284.

### 7.3 医学统计与流行病学

^[^10]^: **World Health Organization.** (2015). *The global prevalence of anaemia in 2011*. Geneva: World Health Organization.


[^1]: **Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, É.** (2011). *Scikit-learn: Machine learning in Python*. **Journal of Machine Learning Research**, 12, 2825-2830.
